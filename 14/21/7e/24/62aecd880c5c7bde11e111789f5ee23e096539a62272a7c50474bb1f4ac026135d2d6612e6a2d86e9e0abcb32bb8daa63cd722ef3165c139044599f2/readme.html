<p><a href="https://travis-ci.org/ValeevGroup/tiledarray"><img src="https://travis-ci.org/ValeevGroup/tiledarray.svg?branch=master" alt="Build Status" /></a> <a href="https://codecov.io/gh/ValeevGroup/tiledarray"><img src="https://codecov.io/gh/ValeevGroup/tiledarray/branch/master/graph/badge.svg" alt="codecov" /></a></p>
<p><img src=https://github.com/ValeevGroup/tiledarray/wiki/images/ta_logo_med.png width=125></p>
<h1 id="synopsis">Synopsis</h1>
<p>TiledArray is a scalable, block-sparse tensor framework for rapid composition of high-performance tensor arithmetic, appearing for example in many-body quantum mechanics. It allows users to compose tensor expressions of arbitrary complexity in native C++ code that closely resembles the standard mathematical notation. The framework is designed to scale from a single multicore computer to a massive distributed-memory multiprocessor.</p>
<p>TiledArray is built on top of MADNESS parallel runtime (MADWorld), part of <a href="https://github.com/m-a-d-n-e-s-s/madness">MADNESS numerical calculus framework</a>.</p>
<p>TiledArray is a work in progress. Its development has been possible thanks to generous support from the U.S. National Science Foundation, the Alfred P. Sloan Foundation, the Camille and Henry Dreyfus Foundation, and the Department of Energy.</p>
<h1 id="design-goals">Design Goals</h1>
<ul>
<li>General-purpose arithmetic on dense and block-sparse tensors;</li>
<li>High-level (math-like) composition as well as full access to low-level data and algorithms, both from C++</li>
<li>Massive shared- and distributed-memory parallelism</li>
<li>Deeply-reusable framework: everything can be customized, from tile types (e.g. to support on-disk or compute-on-the-fly tensors) to how the structure of sparse tensors is described.</li>
</ul>
<h1 id="example-code">Example Code</h1>
<p>The following example expressions are written in C++ with TiledArray. TiledArray use the <a href="http://en.wikipedia.org/wiki/Einstein_notation">Einstein summation convention</a> when evaluating tensor expressions.</p>
<ul>
<li>Matrix-matrix multiplication</li>
</ul>
<p><code>{.cc}    C(&quot;m,n&quot;) = 2.0 * A(&quot;m,k&quot;) * B(&quot;k,n&quot;);</code></p>
<ul>
<li>Matrix-vector multiplication</li>
</ul>
<p><code>{.cc}    C(&quot;n&quot;) = A(&quot;k&quot;) * B(&quot;k,n&quot;);</code></p>
<ul>
<li>A more complex tensor expression</li>
</ul>
<p><code>{.cc}    E(&quot;m,n&quot;) = 2.0 * A(&quot;m,k&quot;) * B(&quot;k,n&quot;) + C(&quot;k,n&quot;) * D(&quot;k,m&quot;);</code></p>
<p>The following application is a minimal example of a distributed-memory matrix multiplcation.</p>
<div class="sourceCode"><pre class="sourceCode cc"><code class="sourceCode cpp"><span class="pp">#include </span><span class="im">&lt;tiledarray.h&gt;</span>

<span class="dt">int</span> main(<span class="dt">int</span> argc, <span class="dt">char</span>** argv) {
  <span class="co">// Initialize the parallel runtime</span>
  TA::World&amp; world = TA::initialize(argc, argv);
  
  <span class="co">// Construct a 2D tiled range structure that defines</span>
  <span class="co">// the tiling of an array. Each dimension contains</span>
  <span class="co">// 10 tiles.</span>
  TA::TiledRange trange = 
      { { <span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">30</span>, <span class="dv">40</span>, <span class="dv">50</span>, <span class="dv">60</span>, <span class="dv">70</span>, <span class="dv">80</span>, <span class="dv">90</span>, <span class="dv">100</span> },
        { <span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">30</span>, <span class="dv">40</span>, <span class="dv">50</span>, <span class="dv">60</span>, <span class="dv">70</span>, <span class="dv">80</span>, <span class="dv">90</span>, <span class="dv">100</span> } };
  
  <span class="co">// Construct and fill the argument arrays with data</span>
  TA::TArrayD A(world, trange);
  TA::TArrayD B(world, trange);
  A.fill_local(<span class="fl">3.0</span>);
  B.fill_local(<span class="fl">2.0</span>);
  
  <span class="co">// Construct the (empty) result array.</span>
  TA::TArrayD C;
  
  <span class="co">// Perform a distributed matrix multiplication</span>
  C(<span class="st">&quot;i,j&quot;</span>) = A(<span class="st">&quot;i,k&quot;</span>) * B(<span class="st">&quot;k,j&quot;</span>);
  
  <span class="co">// Tear down the parallel runtime. </span>
  TA::finalize();
  <span class="cf">return</span> <span class="dv">0</span>;
}</code></pre></div>
<h1 id="performance">Performance</h1>
<p>Parallel performance of TiledArray for multiplication of dense square matrices on <a href="https://www.alcf.anl.gov/mira">Mira</a>, an IBM BlueGene/Q supercomputer at Argonne National Laboratory, compared with that of <a href="https://github.com/solomonik/ctf">Cyclops Tensor Framework</a> and <a href="http://www.netlib.org/scalapack/">ScaLAPACK</a>:</p>
<div class="figure">
<img src="https://github.com/ValeevGroup/tiledarray/wiki/images/BGQtime_TA_CTF_ScaLAPACK.png" alt="MM:TA-vs-CTF-vs-SCALAPACK" />
<p class="caption">MM:TA-vs-CTF-vs-SCALAPACK</p>
</div>
<p>This figure was obtained with the help of an award from <a href="http://www.doeleadershipcomputing.org/incite-program/">the Department of Energy INCITE program</a>.</p>
<p>Excellent parallel scalability is also possible for much more complicated expressions than just a single GEMM, as demonstrated below for the coupled-cluster singles and doubles (CCSD) wave function solver. Parallel speed-up of 1 iteration of CCSD solver for uracil trimer in 6-31G* AO basis was measured on <a href="https://secure.hosting.vt.edu/www.arc.vt.edu/computing/blueridge-sandy-bridge/">&quot;BlueRidge&quot; cluster</a> at Virginia Tech (wall time on one 16-core node = 1290 sec):</p>
<div class="figure">
<img src="https://github.com/ValeevGroup/tiledarray/wiki/images/uracil-trimer-ccsd-blueridge-speedup.png" alt="CCSD:UracilTrimer-speedup" />
<p class="caption">CCSD:UracilTrimer-speedup</p>
</div>
<p>This figure was obtained with the help of an allocation from <a href="https://secure.hosting.vt.edu/www.arc.vt.edu/">Advanced Research Computing</a> at Virginia Tech.</p>
<h1 id="installing-tiledarray">Installing TiledArray</h1>
<p>The short version: assuming that MPI compiler wrappers are in your path, and this is a platform with BLAS/LAPACK installed system-wide in a standard location:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="fu">git</span> clone https://github.com/ValeevGroup/TiledArray.git tiledarray
$ <span class="bu">cd</span> tiledarray
$ <span class="fu">cmake</span> -B build \
    -D CMAKE_INSTALL_PREFIX=/path/to/tiledarray/install \
    -D CMAKE_TOOLCHAIN_FILE=../cmake/toolchains/toolchain-file-for-your-platform.cmake \
    .
$ <span class="fu">cmake</span> --build build
<span class="kw">(</span><span class="ex">optional</span><span class="kw">)</span> $ <span class="fu">cmake</span> --build build --target check
$ <span class="fu">cmake</span> --build build --target install</code></pre></div>
<p>On some standard platforms (e.g. MacOS) the toolchain file can be skipped.</p>
<p>The detailed instructions can be found in <a href="INSTALL.md" class="uri">INSTALL.md</a>.</p>
<h1 id="developers">Developers</h1>
<p>TiledArray is developed by the <a href="http://valeevgroup.github.io/">Valeev Group</a> at <a href="http://www.vt.edu">Virginia Tech</a>.</p>
<h1 id="license">License</h1>
<p>TiledArray is freely available under the terms of the GPL v3+ licence. See the the included LICENSE file for details. If you are interested in using TiledArray under different licensing terms, please contact us.</p>
<h1 id="how-to-cite">How to Cite</h1>
<p>Cite TiledArray as &gt; &quot;TiledArray: A general-purpose scalable block-sparse tensor framework&quot;, Justus A. Calvin and Edward F. Valeev, https://github.com/valeevgroup/tiledarray .</p>
<p>Inner workings of TiledArray are partially described in the following publications: * Justus A. Calvin, Cannada A. Lewis, and Edward F. Valeev, &quot;Scalable Task-Based Algorithm for Multiplication of Block-Rank-Sparse Matrices.&quot;, Proceedings of the 5th Workshop on Irregular Applications: Architectures and Algorithms, http://dx.doi.org/10.1145/2833179.2833186. * Justus A. Calvin and Edward F. Valeev, &quot;Task-Based Algorithm for Matrix Multiplication: A Step Towards Block-Sparse Tensor Computing.&quot; http://arxiv.org/abs/1504.05046 .</p>
<p>The MADNESS parallel runtime is described in the following publication: * Robert J. Harrison, Gregory Beylkin, Florian A. Bischoff, Justus A. Calvin, George I. Fann, Jacob Fosso-Tande, Diego Galindo, Jeff R. Hammond, Rebecca Hartman-Baker, Judith C. Hill, Jun Jia, Jakob S. Kottmann, M-J. Yvonne Ou, Junchen Pei, Laura E. Ratcliff, Matthew G. Reuter, Adam C. Richie-Halford, Nichols A. Romero, Hideo Sekino, William A. Shelton, Bryan E. Sundahl, W. Scott Thornton, Edward F. Valeev, Álvaro Vázquez-Mayagoitia, Nicholas Vence, Takeshi Yanai, and Yukina Yokoi, &quot;madness: A Multiresolution, Adaptive Numerical Environment for Scientific Simulation.&quot;, <em>SIAM J Sci Comput</em> <strong>38</strong>, S123-S142 (2016), http://dx.doi.org/10.1137/15M1026171 .</p>
<h1 id="acknowledgements">Acknowledgements</h1>
<p>Development of TiledArray is made possible by past and present contributions from the National Science Foundation (awards CHE-0847295, CHE-0741927, OCI-1047696, CHE-1362655, ACI-1450262, ACI-1550456), the Alfred P. Sloan Foundation, the Camille and Henry Dreyfus Foundation, the Department of Energy Exascale Computing Project (<a href="https://github.com/NWChemEx-Project">NWChemEx subproject</a>), and the Department of Energy INCITE Program.</p>
