<h1 id="efficient-and-performance-portable-vector-software">Efficient and performance-portable vector software</h1>
<p>Highway is a C++ library that provides portable SIMD/vector intrinsics.</p>
<h2 id="why">Why</h2>
<p>We are passionate about high-performance software. We see major untapped potential in CPUs (servers, mobile, desktops). Highway is for engineers who want to reliably and economically push the boundaries of what is possible in software.</p>
<h2 id="how">How</h2>
<p>CPUs provide SIMD/vector instructions that apply the same operation to multiple data items. This can reduce energy usage e.g. <em>fivefold</em> because fewer instructions are executed. We also often see <em>5-10x</em> speedups.</p>
<p>Highway makes SIMD/vector programming practical and workable according to these guiding principles:</p>
<p><strong>Does what you expect</strong>: Highway is a C++ library with carefully-chosen functions that map well to CPU instructions without extensive compiler transformations. The resulting code is more predictable and robust to code changes/compiler updates than autovectorization.</p>
<p><strong>Works on widely-used platforms</strong>: Highway supports four architectures; the same application code can target eight instruction sets, including those with ‘scalable’ vectors (size unknown at compile time). Highway only requires C++11 and supports four families of compilers. If you would like to use Highway on other platforms, please raise an issue.</p>
<p><strong>Flexible to deploy</strong>: Applications using Highway can run on heterogeneous clouds or client devices, choosing the best available instruction set at runtime. Alternatively, developers may choose to target a single instruction set without any runtime overhead. In both cases, the application code is the same except for swapping <code>HWY_STATIC_DISPATCH</code> with <code>HWY_DYNAMIC_DISPATCH</code> plus one line of code.</p>
<p><strong>Suitable for a variety of domains</strong>: Highway provides an extensive set of operations, used for image processing (floating-point), compression, video analysis, linear algebra, cryptography, sorting and random generation. We recognise that new use-cases may require additional ops and are happy to add them where it makes sense (e.g. no performance cliffs on some architectures). If you would like to discuss, please file an issue.</p>
<p><strong>Rewards data-parallel design</strong>: Highway provides tools such as Gather, MaskedLoad, and FixedTag to enable speedups for legacy data structures. However, the biggest gains are unlocked by designing algorithms and data structures for scalable vectors. Helpful techniques include batching, structure-of-array layouts, and aligned/padded allocations.</p>
<h2 id="examples">Examples</h2>
<p>Online demos using Compiler Explorer:</p>
<ul>
<li><a href="https://gcc.godbolt.org/z/zP7MYe9Yf">multiple targets with dynamic dispatch</a> (recommended)</li>
<li><a href="https://gcc.godbolt.org/z/rGnjMevKG">single target using -m flags</a></li>
</ul>
<p>Projects using Highway: (to add yours, feel free to raise an issue or contact us via the below email)</p>
<ul>
<li><a href="https://github.com/iresearch-toolkit/iresearch/blob/e7638e7a4b99136ca41f82be6edccf01351a7223/core/utils/simd_utils.hpp">iresearch database index</a></li>
<li><a href="https://github.com/libjxl/libjxl">JPEG XL image codec</a></li>
<li><a href="https://github.com/GrokImageCompression/grok">Grok JPEG 2000 image codec</a></li>
<li><a href="https://github.com/google/highway/tree/master/hwy/contrib/sort">vectorized Quicksort</a> (<a href="https://arxiv.org/abs/2205.05982">paper</a>)</li>
</ul>
<h2 id="current-status">Current status</h2>
<h3 id="targets">Targets</h3>
<p>Supported targets: scalar, S-SSE3, SSE4, AVX2, AVX-512, AVX3_DL (~Icelake, requires opt-in by defining <code>HWY_WANT_AVX3_DL</code>), NEON (ARMv7 and v8), SVE, SVE2, WASM SIMD, RISC-V V.</p>
<p><code>HWY_WASM_EMU256</code> is a 2x unrolled version of wasm128 and is enabled if <code>HWY_WANT_WASM2</code> is defined. This will remain supported until it is potentially superseded by a future version of WASM.</p>
<p>SVE was initially tested using farm_sve (see acknowledgments).</p>
<h3 id="versioning">Versioning</h3>
<p>Highway releases aim to follow the semver.org system (MAJOR.MINOR.PATCH), incrementing MINOR after backward-compatible additions and PATCH after backward-compatible fixes. We recommend using releases (rather than the Git tip) because they are tested more extensively, see below.</p>
<p>The current version 1.0 signals an increased focus on backwards compatibility. Applications using documented functionality will remain compatible with future updates that have the same major version number.</p>
<h3 id="testing">Testing</h3>
<p>Continuous integration tests build with a recent version of Clang (running on native x86, or QEMU for RVV and ARM) and MSVC 2019 (v19.28, running on native x86).</p>
<p>Before releases, we also test on x86 with Clang and GCC, and ARMv7/8 via GCC cross-compile. See the <a href="g3doc/release_testing_process.md">testing process</a> for details.</p>
<h3 id="related-modules">Related modules</h3>
<p>The <code>contrib</code> directory contains SIMD-related utilities: an image class with aligned rows, a math library (16 functions already implemented, mostly trigonometry), and functions for computing dot products and sorting.</p>
<h3 id="other-libraries">Other libraries</h3>
<p>If you only require x86 support, you may also use Agner Fog’s <a href="https://github.com/vectorclass">VCL vector class library</a>. It includes many functions including a complete math library.</p>
<p>If you have existing code using x86/NEON intrinsics, you may be interested in <a href="https://github.com/simd-everywhere/simde">SIMDe</a>, which emulates those intrinsics using other platforms’ intrinsics or autovectorization.</p>
<h2 id="installation">Installation</h2>
<p>This project uses CMake to generate and build. In a Debian-based system you can install it via:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt install cmake</span></code></pre></div>
<p>Highway’s unit tests use <a href="https://github.com/google/googletest">googletest</a>. By default, Highway’s CMake downloads this dependency at configuration time. You can disable this by setting the <code>HWY_SYSTEM_GTEST</code> CMake variable to ON and installing gtest separately:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt install libgtest-dev</span></code></pre></div>
<p>Running cross-compiled tests requires support from the OS, which on Debian is provided by the <code>qemu-user-binfmt</code> package.</p>
<p>To build Highway as a shared or static library (depending on BUILD_SHARED_LIBS), the standard CMake workflow can be used:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> <span class="at">-p</span> build <span class="kw">&amp;&amp;</span> <span class="bu">cd</span> build</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cmake</span> ..</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="fu">make</span> <span class="at">-j</span> <span class="kw">&amp;&amp;</span> <span class="fu">make</span> test</span></code></pre></div>
<p>Or you can run <code>run_tests.sh</code> (<code>run_tests.bat</code> on Windows).</p>
<p>Bazel is also supported for building, but it is not as widely used/tested.</p>
<p>When building for Arm v7, a limitation of current compilers requires you to add <code>-DHWY_CMAKE_ARM7:BOOL=ON</code> to the CMake command line; see #834 and #1032. We understand that work is underway to remove this limitation.</p>
<h2 id="quick-start">Quick start</h2>
<p>You can use the <code>benchmark</code> inside examples/ as a starting point.</p>
<p>A <a href="g3doc/quick_reference.md">quick-reference page</a> briefly lists all operations and their parameters, and the <a href="g3doc/instruction_matrix.pdf">instruction_matrix</a> indicates the number of instructions per operation.</p>
<p>The <a href="g3doc/faq.md">FAQ</a> answers questions about portability, API design and where to find more information.</p>
<p>We recommend using full SIMD vectors whenever possible for maximum performance portability. To obtain them, pass a <code>ScalableTag&lt;float&gt;</code> (or equivalently <code>HWY_FULL(float)</code>) tag to functions such as <code>Zero/Set/Load</code>. There are two alternatives for use-cases requiring an upper bound on the lanes:</p>
<ul>
<li><p>For up to <code>N</code> lanes, specify <code>CappedTag&lt;T, N&gt;</code> or the equivalent <code>HWY_CAPPED(T, N)</code>. The actual number of lanes will be <code>N</code> rounded down to the nearest power of two, such as 4 if <code>N</code> is 5, or 8 if <code>N</code> is 8. This is useful for data structures such as a narrow matrix. A loop is still required because vectors may actually have fewer than <code>N</code> lanes.</p></li>
<li><p>For exactly a power of two <code>N</code> lanes, specify <code>FixedTag&lt;T, N&gt;</code>. The largest supported <code>N</code> depends on the target, but is guaranteed to be at least <code>16/sizeof(T)</code>.</p></li>
</ul>
<p>Due to ADL restrictions, user code calling Highway ops must either: * Reside inside <code>namespace hwy { namespace HWY_NAMESPACE {</code>; or * prefix each op with an alias such as <code>namespace hn = hwy::HWY_NAMESPACE;     hn::Add()</code>; or * add using-declarations for each op used: <code>using hwy::HWY_NAMESPACE::Add;</code>.</p>
<p>Additionally, each function that calls Highway ops (such as <code>Load</code>) must either be prefixed with <code>HWY_ATTR</code>, OR reside between <code>HWY_BEFORE_NAMESPACE()</code> and <code>HWY_AFTER_NAMESPACE()</code>. Lambda functions currently require <code>HWY_ATTR</code> before their opening brace.</p>
<p>The entry points into code using Highway differ slightly depending on whether they use static or dynamic dispatch.</p>
<ul>
<li><p>For static dispatch, <code>HWY_TARGET</code> will be the best available target among <code>HWY_BASELINE_TARGETS</code>, i.e. those allowed for use by the compiler (see <a href="g3doc/quick_reference.md">quick-reference</a>). Functions inside <code>HWY_NAMESPACE</code> can be called using <code>HWY_STATIC_DISPATCH(func)(args)</code> within the same module they are defined in. You can call the function from other modules by wrapping it in a regular function and declaring the regular function in a header.</p></li>
<li><p>For dynamic dispatch, a table of function pointers is generated via the <code>HWY_EXPORT</code> macro that is used by <code>HWY_DYNAMIC_DISPATCH(func)(args)</code> to call the best function pointer for the current CPU’s supported targets. A module is automatically compiled for each target in <code>HWY_TARGETS</code> (see <a href="g3doc/quick_reference.md">quick-reference</a>) if <code>HWY_TARGET_INCLUDE</code> is defined and <code>foreach_target.h</code> is included.</p></li>
</ul>
<p>When using dynamic dispatch, <code>foreach_target.h</code> is included from translation units (.cc files), not headers. Headers containing vector code shared between several translation units require a special include guard, for example the following taken from <code>examples/skeleton-inl.h</code>:</p>
<pre><code>#if defined(HIGHWAY_HWY_EXAMPLES_SKELETON_INL_H_) == defined(HWY_TARGET_TOGGLE)
#ifdef HIGHWAY_HWY_EXAMPLES_SKELETON_INL_H_
#undef HIGHWAY_HWY_EXAMPLES_SKELETON_INL_H_
#else
#define HIGHWAY_HWY_EXAMPLES_SKELETON_INL_H_
#endif

#include &quot;hwy/highway.h&quot;
// Your vector code
#endif</code></pre>
<p>By convention, we name such headers <code>-inl.h</code> because their contents (often function templates) are usually inlined.</p>
<h2 id="compiler-flags">Compiler flags</h2>
<p>Applications should be compiled with optimizations enabled - without inlining, SIMD code may slow down by factors of 10 to 100. For clang and GCC, <code>-O2</code> is generally sufficient.</p>
<p>For MSVC, we recommend compiling with <code>/Gv</code> to allow non-inlined functions to pass vector arguments in registers. If intending to use the AVX2 target together with half-width vectors (e.g. for <code>PromoteTo</code>), it is also important to compile with <code>/arch:AVX2</code>. This seems to be the only way to generate VEX-encoded SSE4 instructions on MSVC. Otherwise, mixing VEX-encoded AVX2 instructions and non-VEX SSE4 may cause severe performance degradation. Unfortunately, the resulting binary will then require AVX2. Note that no such flag is needed for clang and GCC because they support target-specific attributes, which we use to ensure proper VEX code generation for AVX2 targets.</p>
<h2 id="strip-mining-loops">Strip-mining loops</h2>
<p>To vectorize a loop, “strip-mining” transforms it into an outer loop and inner loop with number of iterations matching the preferred vector width.</p>
<p>In this section, let <code>T</code> denote the element type, <code>d = ScalableTag&lt;T&gt;</code>, <code>count</code> the number of elements to process, and <code>N = Lanes(d)</code> the number of lanes in a full vector. Assume the loop body is given as a function <code>template&lt;bool partial, class D&gt; void LoopBody(D d, size_t index, size_t max_n)</code>.</p>
<p>Highway offers several ways to express loops where <code>N</code> need not divide <code>count</code>:</p>
<ul>
<li><p>Ensure all inputs/outputs are padded. Then the loop is simply</p>
<pre><code>for (size_t i = 0; i &lt; count; i += N) LoopBody&lt;false&gt;(d, i, 0);</code></pre>
<p>Here, the template parameter and second function argument are not needed.</p>
<p>This is the preferred option, unless <code>N</code> is in the thousands and vector operations are pipelined with long latencies. This was the case for supercomputers in the 90s, but nowadays ALUs are cheap and we see most implementations split vectors into 1, 2 or 4 parts, so there is little cost to processing entire vectors even if we do not need all their lanes. Indeed this avoids the (potentially large) cost of predication or partial loads/stores on older targets, and does not duplicate code.</p></li>
<li><p>Process whole vectors and include previously processed elements in the last vector: <code>for (size_t i = 0; i &lt; count; i += N) LoopBody&lt;false&gt;(d, HWY_MIN(i, count - N), 0);</code></p>
<p>This is the second preferred option provided that <code>count &gt;= N</code> and <code>LoopBody</code> is idempotent. Some elements might be processed twice, but a single code path and full vectorization is usually worth it. Even if <code>count &lt; N</code>, it usually makes sense to pad inputs/outputs up to <code>N</code>.</p></li>
<li><p>Use the <code>Transform*</code> functions in hwy/contrib/algo/transform-inl.h. This takes care of the loop and remainder handling and you simply define a generic lambda function (C++14) or functor which receives the current vector from the input/output array, plus optionally vectors from up to two extra input arrays, and returns the value to write to the input/output array.</p>
<p>Here is an example implementing the BLAS function SAXPY (<code>alpha * x + y</code>):</p>
<pre><code>Transform1(d, x, n, y, [](auto d, const auto v, const auto v1) HWY_ATTR {
  return MulAdd(Set(d, alpha), v, v1);
});</code></pre></li>
<li><p>Process whole vectors as above, followed by a scalar loop:</p>
<pre><code>size_t i = 0;
for (; i + N &lt;= count; i += N) LoopBody&lt;false&gt;(d, i, 0);
for (; i &lt; count; ++i) LoopBody&lt;false&gt;(CappedTag&lt;T, 1&gt;(), i, 0);</code></pre>
<p>The template parameter and second function arguments are again not needed.</p>
<p>This avoids duplicating code, and is reasonable if <code>count</code> is large. If <code>count</code> is small, the second loop may be slower than the next option.</p></li>
<li><p>Process whole vectors as above, followed by a single call to a modified <code>LoopBody</code> with masking:</p>
<pre><code>size_t i = 0;
for (; i + N &lt;= count; i += N) {
  LoopBody&lt;false&gt;(d, i, 0);
}
if (i &lt; count) {
  LoopBody&lt;true&gt;(d, i, count - i);
}</code></pre>
<p>Now the template parameter and third function argument can be used inside <code>LoopBody</code> to non-atomically ‘blend’ the first <code>num_remaining</code> lanes of <code>v</code> with the previous contents of memory at subsequent locations: <code>BlendedStore(v, FirstN(d, num_remaining), d, pointer);</code>. Similarly, <code>MaskedLoad(FirstN(d, num_remaining), d, pointer)</code> loads the first <code>num_remaining</code> elements and returns zero in other lanes.</p>
<p>This is a good default when it is infeasible to ensure vectors are padded, but is only safe <code>#if !HWY_MEM_OPS_MIGHT_FAULT</code>! In contrast to the scalar loop, only a single final iteration is needed. The increased code size from two loop bodies is expected to be worthwhile because it avoids the cost of masking in all but the final iteration.</p></li>
</ul>
<h2 id="additional-resources">Additional resources</h2>
<ul>
<li><a href="g3doc/highway_intro.pdf">Highway introduction (slides)</a></li>
<li><a href="g3doc/instruction_matrix.pdf">Overview of instructions per operation on different architectures</a></li>
<li><a href="g3doc/design_philosophy.md">Design philosophy and comparison</a></li>
<li><a href="g3doc/impl_details.md">Implementation details</a></li>
</ul>
<h2 id="acknowledgments">Acknowledgments</h2>
<p>We have used <a href="https://gitlab.inria.fr/bramas/farm-sve">farm-sve</a> by Berenger Bramas; it has proved useful for checking the SVE port on an x86 development machine.</p>
<p>This is not an officially supported Google product. Contact: janwas@google.com</p>
